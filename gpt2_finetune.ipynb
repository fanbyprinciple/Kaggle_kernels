{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt2_finetune",
      "provenance": [],
      "authorship_tag": "ABX9TyMuWSSns6Pb7ep/YT4nTVHR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fanbyprinciple/kaggle_kernels/blob/master/gpt2_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jE4dgznCkot"
      },
      "source": [
        "### Getting dataset\n",
        "\n",
        "Getting the large movie dataset\n",
        "\n",
        "https://colab.research.google.com/github/gmihaila/ml_things/blob/master/notebooks/pytorch/gpt2_finetune_classification.ipynb#scrollTo=gjr_J342tOPq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHB-irK5AmPR"
      },
      "source": [
        "# download the dataset\n",
        "!wget -q -nc http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "# unzip it\n",
        "!tar -zxf /content/aclImdb_v1.tar.gz"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJVjNqzpC1kf",
        "outputId": "e30fcc9a-91fe-478d-c880-dd0ee579bf0d"
      },
      "source": [
        "# Install transformers library.\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "# Install helper functions.\n",
        "!pip install -q git+https://github.com/gmihaila/ml_things.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 895 kB 11.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 34.3 MB/s \n",
            "\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.3 MB 26.0 MB/s \n",
            "\u001b[?25h  Building wheel for ml-things (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkIB3sRFD_iF"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from ml_things import plot_dict, plot_confusion_matrix, fix_text\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from transformers import (set_seed,\n",
        "                          TrainingArguments,\n",
        "                          Trainer,\n",
        "                          GPT2Config,\n",
        "                          GPT2Tokenizer,\n",
        "                          AdamW, \n",
        "                          get_linear_schedule_with_warmup,\n",
        "                          GPT2ForSequenceClassification)\n",
        "set_seed(123)\n",
        "\n",
        "epochs=4\n",
        "batch_size=32\n",
        "\n",
        "max_length = 60\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_name_or_path = 'gpt2'\n",
        "\n",
        "label_ids = {'neg':0, 'pos':1}\n",
        "\n",
        "n_labels = len(label_ids)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qvjW_OBFgeG"
      },
      "source": [
        "class MovieReviewsDataset(Dataset):\n",
        "  def __init__(self, path, use_tokenizer):\n",
        "    if not os.path.isdir(path):\n",
        "      raise ValueError('Invalid `path` variable!')\n",
        "    self.texts = []\n",
        "    self.labels = []\n",
        "\n",
        "    for label in ['pos', 'neg']:\n",
        "      sentiment_path = os.path.join(path, labels)\n",
        "\n",
        "      files_name = os.listdir(sentiment_path)\n",
        "\n",
        "      for file_name in tqdm(files_names, desc=f'{label} files'):\n",
        "        file_path = os.path.join(sentiment_path, file_name)\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}