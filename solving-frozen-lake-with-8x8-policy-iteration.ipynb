{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/fanbyprinciple/solving-frozen-lake-with-8x8-policy-iteration?scriptVersionId=101579944\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"7f434173","metadata":{"papermill":{"duration":0.002609,"end_time":"2022-07-23T16:09:25.585361","exception":false,"start_time":"2022-07-23T16:09:25.582752","status":"completed"},"tags":[]},"source":["This is taken from packt publishing : https://github.com/PacktPublishing/Reinforcement-Learning-Algorithms-with-Python/blob/master/Chapter03/frozenlake8x8_policyiteration.py"]},{"cell_type":"code","execution_count":1,"id":"65c3d77b","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-07-23T16:09:25.592917Z","iopub.status.busy":"2022-07-23T16:09:25.591838Z","iopub.status.idle":"2022-07-23T16:09:25.926723Z","shell.execute_reply":"2022-07-23T16:09:25.925558Z"},"papermill":{"duration":0.341384,"end_time":"2022-07-23T16:09:25.929401","exception":false,"start_time":"2022-07-23T16:09:25.588017","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","import gym\n","\n","def eval_state_action(V, s, a, gamma=0.99):\n","    return np.sum([p * (rew + gamma*V[next_s]) for p, next_s, rew, _ in env.P[s][a]])\n","\n","def policy_evaluation(V, policy, eps=0.0001):\n","    '''\n","    Policy evaluation. Update the value function until it reach a steady state\n","    '''\n","    while True:\n","        delta = 0\n","        # loop over all states\n","        for s in range(nS):\n","            old_v = V[s]\n","            # update V[s] using the Bellman equation\n","            V[s] = eval_state_action(V, s, policy[s])\n","            delta = max(delta, np.abs(old_v - V[s]))\n","\n","        if delta < eps:\n","            break\n","\n","def policy_improvement(V, policy):\n","    '''\n","    Policy improvement. Update the policy based on the value function\n","    '''\n","    policy_stable = True\n","    for s in range(nS):\n","        old_a = policy[s]\n","        # update the policy with the action that bring to the highest state value\n","        policy[s] = np.argmax([eval_state_action(V, s, a) for a in range(nA)])\n","        if old_a != policy[s]: \n","            policy_stable = False\n","\n","    return policy_stable\n","\n","\n","def run_episodes(env, policy, num_games=100):\n","    '''\n","    Run some games to test a policy\n","    '''\n","    tot_rew = 0\n","    state = env.reset()\n","\n","    for _ in range(num_games):\n","        done = False\n","        while not done:\n","            # select the action accordingly to the policy\n","#             print(env.step(policy[state]))\n","#             break\n","            next_state, reward, done,_,_ = env.step(policy[state])\n","                \n","            state = next_state\n","            tot_rew += reward \n","            if done:\n","                state = env.reset()\n","\n","    print('Won %i of %i games!'%(tot_rew, num_games))\n","\n"]},{"cell_type":"code","execution_count":2,"id":"61ac3792","metadata":{"execution":{"iopub.execute_input":"2022-07-23T16:09:25.934188Z","iopub.status.busy":"2022-07-23T16:09:25.933835Z","iopub.status.idle":"2022-07-23T16:09:26.06698Z","shell.execute_reply":"2022-07-23T16:09:26.065714Z"},"papermill":{"duration":0.139567,"end_time":"2022-07-23T16:09:26.070794","exception":false,"start_time":"2022-07-23T16:09:25.931227","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Converged after 7 policy iterations\n","Won 84 of 100 games!\n","[[0.54091157 0.49730529 0.46893217 0.4549538 ]\n"," [0.55745963 0.         0.35758788 0.        ]\n"," [0.59098844 0.64249454 0.61469305 0.        ]\n"," [0.         0.74131715 0.86263385 0.        ]]\n","[[0. 3. 3. 3.]\n"," [0. 0. 0. 0.]\n"," [3. 1. 0. 0.]\n"," [0. 2. 1. 0.]]\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/opt/conda/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}],"source":["    # create the environment\n","    env = gym.make('FrozenLake-v1')\n","    # enwrap it to have additional information from it\n","    env = env.unwrapped\n","\n","    # spaces dimension\n","    nA = env.action_space.n\n","    nS = env.observation_space.n\n","    \n","    # initializing value function and policy\n","    V = np.zeros(nS)\n","    policy = np.zeros(nS)\n","\n","    # some useful variable\n","    policy_stable = False\n","    it = 0\n","\n","    while not policy_stable:\n","        policy_evaluation(V, policy)\n","        policy_stable = policy_improvement(V, policy)\n","        it += 1\n","\n","    print('Converged after %i policy iterations'%(it))\n","    run_episodes(env, policy)\n","    print(V.reshape((4,4)))\n","    print(policy.reshape((4,4)))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":10.77425,"end_time":"2022-07-23T16:09:26.694307","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-07-23T16:09:15.920057","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}